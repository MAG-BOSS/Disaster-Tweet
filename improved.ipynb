{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:15.693642Z",
     "iopub.status.busy": "2020-12-31T10:49:15.692764Z",
     "iopub.status.idle": "2020-12-31T10:49:15.700462Z",
     "shell.execute_reply": "2020-12-31T10:49:15.699075Z"
    },
    "papermill": {
     "duration": 0.028606,
     "end_time": "2020-12-31T10:49:15.700674",
     "exception": false,
     "start_time": "2020-12-31T10:49:15.672068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:15.739147Z",
     "iopub.status.busy": "2020-12-31T10:49:15.738473Z",
     "iopub.status.idle": "2020-12-31T10:49:15.798983Z",
     "shell.execute_reply": "2020-12-31T10:49:15.798377Z"
    },
    "papermill": {
     "duration": 0.080517,
     "end_time": "2020-12-31T10:49:15.799107",
     "exception": false,
     "start_time": "2020-12-31T10:49:15.718590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:15.826487Z",
     "iopub.status.busy": "2020-12-31T10:49:15.825859Z",
     "iopub.status.idle": "2020-12-31T10:49:15.846595Z",
     "shell.execute_reply": "2020-12-31T10:49:15.845871Z"
    },
    "papermill": {
     "duration": 0.03687,
     "end_time": "2020-12-31T10:49:15.846709",
     "exception": false,
     "start_time": "2020-12-31T10:49:15.809839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n",
    "#test_data.head()\n",
    "test= test_data\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:15.873806Z",
     "iopub.status.busy": "2020-12-31T10:49:15.873136Z",
     "iopub.status.idle": "2020-12-31T10:49:17.685798Z",
     "shell.execute_reply": "2020-12-31T10:49:17.685169Z"
    },
    "papermill": {
     "duration": 1.82895,
     "end_time": "2020-12-31T10:49:17.685907",
     "exception": false,
     "start_time": "2020-12-31T10:49:15.856957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>2533</td>\n",
       "      <td>0.332720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <td>61</td>\n",
       "      <td>0.008013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total   Percent\n",
       "location   2533  0.332720\n",
       "keyword      61  0.008013\n",
       "target        0  0.000000\n",
       "text          0  0.000000\n",
       "id            0  0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#get total count of data including missing data\n",
    "total = data_train.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "#get percent of missing data relevant to all data\n",
    "percent = (data_train.isnull().sum()/data_train.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(data_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:17.725310Z",
     "iopub.status.busy": "2020-12-31T10:49:17.724575Z",
     "iopub.status.idle": "2020-12-31T10:49:17.728949Z",
     "shell.execute_reply": "2020-12-31T10:49:17.727453Z"
    },
    "papermill": {
     "duration": 0.02893,
     "end_time": "2020-12-31T10:49:17.729139",
     "exception": false,
     "start_time": "2020-12-31T10:49:17.700209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location and keyword columns droped successfully\n"
     ]
    }
   ],
   "source": [
    "test = test.drop(['location','keyword'],axis=1)\n",
    "data_train = data_train.drop(['location','keyword'], axis=1)\n",
    "\n",
    "print(\"location and keyword columns droped successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:17.760861Z",
     "iopub.status.busy": "2020-12-31T10:49:17.759877Z",
     "iopub.status.idle": "2020-12-31T10:49:17.767493Z",
     "shell.execute_reply": "2020-12-31T10:49:17.768072Z"
    },
    "papermill": {
     "duration": 0.026776,
     "end_time": "2020-12-31T10:49:17.768214",
     "exception": false,
     "start_time": "2020-12-31T10:49:17.741438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id column droped successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = test.drop('id',axis=1)\n",
    "data_train = data_train.drop('id', axis=1)\n",
    "print(\"id column droped successfully\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:17.804256Z",
     "iopub.status.busy": "2020-12-31T10:49:17.803373Z",
     "iopub.status.idle": "2020-12-31T10:49:17.808051Z",
     "shell.execute_reply": "2020-12-31T10:49:17.807235Z"
    },
    "papermill": {
     "duration": 0.027782,
     "end_time": "2020-12-31T10:49:17.808191",
     "exception": false,
     "start_time": "2020-12-31T10:49:17.780409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                 Just happened a terrible car crash\n",
       "1  Heard about #earthquake is different cities, s...\n",
       "2  there is a forest fire at spot pond, geese are...\n",
       "3           Apocalypse lighting. #Spokane #wildfires\n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:17.860043Z",
     "iopub.status.busy": "2020-12-31T10:49:17.858185Z",
     "iopub.status.idle": "2020-12-31T10:49:59.940621Z",
     "shell.execute_reply": "2020-12-31T10:49:59.941155Z"
    },
    "papermill": {
     "duration": 42.113822,
     "end_time": "2020-12-31T10:49:59.941283",
     "exception": false,
     "start_time": "2020-12-31T10:49:17.827461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus created successfully\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "corpus  = []\n",
    "pstem = PorterStemmer()\n",
    "for i in range(data_train['text'].shape[0]):\n",
    "    #Remove unwanted words\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", ' ', data_train['text'][i])\n",
    "    #Transform words to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    #Remove stopwords then Stemming it\n",
    "    tweet = [pstem.stem(word) for word in tweet if not word in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    #Append cleaned tweet to corpus\n",
    "    corpus.append(tweet)\n",
    "    \n",
    "corpus2  = []\n",
    "pstem2 = PorterStemmer()\n",
    "for i in range(test['text'].shape[0]):\n",
    "    #Remove unwanted words\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", ' ', test['text'][i])\n",
    "    #Transform words to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    #Remove stopwords then Stemming it\n",
    "    tweet = [pstem2.stem(word) for word in tweet if not word in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    #Append cleaned tweet to corpus\n",
    "    corpus2.append(tweet)\n",
    "    \n",
    "print(\"Corpus created successfully\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T10:49:59.999520Z",
     "iopub.status.busy": "2020-12-31T10:49:59.989004Z",
     "iopub.status.idle": "2020-12-31T10:50:00.072464Z",
     "shell.execute_reply": "2020-12-31T10:50:00.070984Z"
    },
    "papermill": {
     "duration": 0.117378,
     "end_time": "2020-12-31T10:50:00.072799",
     "exception": false,
     "start_time": "2020-12-31T10:49:59.955421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "#Create our dictionary \n",
    "uniqueWordFrequents = {}\n",
    "for tweet in corpus:\n",
    "    for word in tweet.split():\n",
    "        if(word in uniqueWordFrequents.keys()):\n",
    "            uniqueWordFrequents[word] += 1\n",
    "        else:\n",
    "            uniqueWordFrequents[word] = 1\n",
    "            \n",
    "#Convert dictionary to dataFrame\n",
    "uniqueWordFrequents = pd.DataFrame.from_dict(uniqueWordFrequents,orient='index',columns=['Word Frequent'])\n",
    "uniqueWordFrequents.sort_values(by=['Word Frequent'], inplace=True, ascending=False)\n",
    "#uniqueWordFrequents.head(10)\n",
    "\n",
    "uniqueWordFrequents2 = {}\n",
    "for tweet in corpus2:\n",
    "    for word in tweet.split():\n",
    "        if(word in uniqueWordFrequents2.keys()):\n",
    "            uniqueWordFrequents2[word] += 1\n",
    "        else:\n",
    "            uniqueWordFrequents2[word] = 1\n",
    "            \n",
    "#Convert dictionary to dataFrame\n",
    "uniqueWordFrequents2 = pd.DataFrame.from_dict(uniqueWordFrequents2,orient='index',columns=['Word Frequent'])\n",
    "uniqueWordFrequents2.sort_values(by=['Word Frequent'], inplace=True, ascending=False)\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T10:50:00.122155Z",
     "iopub.status.busy": "2020-12-31T10:50:00.120849Z",
     "iopub.status.idle": "2020-12-31T10:50:00.141437Z",
     "shell.execute_reply": "2020-12-31T10:50:00.140465Z"
    },
    "papermill": {
     "duration": 0.04798,
     "end_time": "2020-12-31T10:50:00.141563",
     "exception": false,
     "start_time": "2020-12-31T10:50:00.093583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(787, 1)\n",
      "(299, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word Frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rememb</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word Frequent\n",
       "co                2071\n",
       "http              2059\n",
       "like               180\n",
       "fire               171\n",
       "amp                166\n",
       "...                ...\n",
       "pay                 20\n",
       "content             20\n",
       "head                20\n",
       "open                20\n",
       "rememb              20\n",
       "\n",
       "[299 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWordFrequents = uniqueWordFrequents[uniqueWordFrequents['Word Frequent'] >= 20]\n",
    "print(uniqueWordFrequents.shape)\n",
    "uniqueWordFrequents\n",
    "\n",
    "uniqueWordFrequents2 = uniqueWordFrequents2[uniqueWordFrequents2['Word Frequent'] >= 20]\n",
    "print(uniqueWordFrequents2.shape)\n",
    "uniqueWordFrequents2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T10:50:00.191279Z",
     "iopub.status.busy": "2020-12-31T10:50:00.185723Z",
     "iopub.status.idle": "2020-12-31T10:50:00.442381Z",
     "shell.execute_reply": "2020-12-31T10:50:00.443071Z"
    },
    "papermill": {
     "duration": 0.286839,
     "end_time": "2020-12-31T10:50:00.443250",
     "exception": false,
     "start_time": "2020-12-31T10:50:00.156411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "counVec = CountVectorizer(max_features = uniqueWordFrequents.shape[0])\n",
    "bagOfWords = counVec.fit_transform(corpus).toarray()\n",
    "\n",
    "counVec2 = CountVectorizer(max_features = uniqueWordFrequents2.shape[0])\n",
    "bagOfWords2 = counVec2.fit_transform(corpus2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-31T10:50:00.495533Z",
     "iopub.status.busy": "2020-12-31T10:50:00.494628Z",
     "iopub.status.idle": "2020-12-31T10:50:02.960205Z",
     "shell.execute_reply": "2020-12-31T10:50:02.959508Z"
    },
    "papermill": {
     "duration": 2.495021,
     "end_time": "2020-12-31T10:50:02.960317",
     "exception": false,
     "start_time": "2020-12-31T10:50:00.465296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 787 and input n_features is 299 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c790747da00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model trained\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_data2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecisionTreeModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagOfWords2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'PassengerId'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPassengerId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Survived'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \"\"\"\n\u001b[1;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    397\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 787 and input n_features is 299 "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = bagOfWords\n",
    "y = data_train['target']\n",
    "decisionTreeModel = DecisionTreeClassifier(criterion= 'entropy',\n",
    "                                           max_depth = None, \n",
    "                                           splitter='best', \n",
    "                                           random_state=55)\n",
    "\n",
    "decisionTreeModel.fit(X,y)\n",
    "print(\"model trained\")\n",
    "test_data2 = test_data['text']\n",
    "predictions = decisionTreeModel.predict(bagOfWords2)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "print(output)\n",
    "#output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 52.200302,
   "end_time": "2020-12-31T10:50:03.085826",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-31T10:49:10.885524",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
